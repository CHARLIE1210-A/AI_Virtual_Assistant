{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3685e64e-776f-4af2-b052-6a3d9f44e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fb612f-cdf0-45a3-8f6d-f652e0ae9097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Recording finished.\n",
      "Audio saved to recorded_audio.wav\n"
     ]
    }
   ],
   "source": [
    "# Set parameters for recording\n",
    "duration = 5  # seconds\n",
    "sample_rate = 44100  # Hz\n",
    "\n",
    "def record_audio(duration, sample_rate):\n",
    "    print(\"Recording started...\")\n",
    "    # Record audio using the sounddevice library\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float64')\n",
    "    sd.wait()  # Wait until the recording is finished\n",
    "    print(\"Recording finished.\")\n",
    "    return audio_data\n",
    "\n",
    "# Function to save recorded audio to a .wav file\n",
    "def save_audio(filename, audio_data, sample_rate):\n",
    "    # Normalize the audio to 16-bit PCM format\n",
    "    audio_data = (audio_data * 32767).astype(np.int16)\n",
    "    wav.write(filename, sample_rate, audio_data)\n",
    "    print(f\"Audio saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831ff59-4364-415c-bf1b-33b27c77761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record and save the audio\n",
    "audio_data = record_audio(duration, sample_rate)\n",
    "save_audio(\"recorded_audio.wav\", audio_data, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9eb4fa9-0507-41af-8d82-779ab0bb8020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playback finished.\n"
     ]
    }
   ],
   "source": [
    "def play_audio(filename):\n",
    "    # Read the audio file\n",
    "    sample_rate, audio_data = wav.read(filename)\n",
    "    \n",
    "    # Play the audio using sounddevice\n",
    "    sd.play(audio_data, samplerate=sample_rate)\n",
    "    sd.wait()  # Wait until playback is finished\n",
    "    print(\"Playback finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c7162a3-c372-4d2d-8dfb-74864ba596a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playback finished.\n"
     ]
    }
   ],
   "source": [
    "# Play the saved audio file\n",
    "play_audio(\"recorded_audio.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352eb3f-8ac4-4d59-9c0f-37ba7346e3bc",
   "metadata": {},
   "source": [
    "### Input Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ee08d55-9604-4e81-8c72-e1b7ec7e23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio = \"recorded_audio.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4004d8e-cf39-49a7-99bc-8eec4857a7a7",
   "metadata": {},
   "source": [
    "### Basic Noise Reduction using pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172c3d7-01d7-43ab-b1aa-2cbb5851a356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Load the audio file\n",
    "audio = AudioSegment.from_file(\"recorded_audio.wav\")\n",
    "\n",
    "# Apply low-pass filter to remove high-frequency noise\n",
    "filtered_audio = audio.low_pass_filter(3000)  # Cut off frequencies above 3000Hz\n",
    "\n",
    "# Export the filtered audio\n",
    "filtered_audio.export(\"output_audio1.wav\", format=\"wav\")\n",
    "\n",
    "# Play the filtered audio\n",
    "play(filtered_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b3e35f9-37d2-4acc-8f20-3c3523be11e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playback finished.\n"
     ]
    }
   ],
   "source": [
    "import noisereduce as nr\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Load the noisy audio file\n",
    "data, rate = librosa.load(input_audio, sr=None)\n",
    "\n",
    "# Perform noise reduction using spectral subtraction\n",
    "reduced_noise_audio = nr.reduce_noise(y=data, sr=rate)\n",
    "\n",
    "# Save the reduced noise audio\n",
    "sf.write(\"output_audio2.wav\", reduced_noise_audio, rate)\n",
    "play_audio(\"output_audio2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ae11a0d-2927-4157-a224-f17524acf564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "Playback finished.\n"
     ]
    }
   ],
   "source": [
    "import webrtcvad\n",
    "import wave\n",
    "\n",
    "# Load the audio file\n",
    "def read_wave(path):\n",
    "    with wave.open(path, 'rb') as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1  # mono\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2  # 16-bit\n",
    "        sample_rate = wf.getframerate()\n",
    "        print(f'Sample rate: {sample_rate}')\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)  # common sampling rates\n",
    "        frames = wf.readframes(wf.getnframes())\n",
    "    return frames, sample_rate\n",
    "\n",
    "# Save the output audio\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    with wave.open(path, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "# Perform Voice Activity Detection\n",
    "def vad_filter(input_file, output_file, aggressiveness=3):\n",
    "    audio, sample_rate = read_wave(input_file)\n",
    "    vad = webrtcvad.Vad(aggressiveness)  # aggressiveness 0-3\n",
    "    frame_duration = 10  # in ms\n",
    "    frame_size = int(sample_rate * frame_duration / 1000 * 2)\n",
    "    segments = []\n",
    "    \n",
    "    for i in range(0, len(audio), frame_size):\n",
    "        frame = audio[i:i + frame_size]\n",
    "        if vad.is_speech(frame, sample_rate):\n",
    "            segments.append(frame)\n",
    "\n",
    "    filtered_audio = b''.join(segments)\n",
    "    write_wave(output_file, filtered_audio, sample_rate)\n",
    "\n",
    "# Run VAD\n",
    "\n",
    "# Load the audio file (original sample rate is detected automatically)\n",
    "audio_data, original_sample_rate = librosa.load(input_audio, sr=None)\n",
    "\n",
    "# Resample the audio to the desired sample rate (e.g., 16000 Hz)\n",
    "target_sample_rate = 32000\n",
    "audio_data_resampled = librosa.resample(audio_data, orig_sr=original_sample_rate, target_sr=target_sample_rate)\n",
    "\n",
    "# Save the resampled audio\n",
    "sf.write(\"output_audio_data_resampled.wav\", audio_data_resampled, target_sample_rate)\n",
    "\n",
    "vad_filter(\"output_audio_data_resampled.wav\", 'output_audio3.wav')\n",
    "play_audio(\"output_audio3.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4e087-6198-49f0-9ad0-635376af8460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Load audio file\n",
    "audio, sr = librosa.load(input_audio, sr=16000)\n",
    "\n",
    "# Load pre-trained DNS model (download the model from Microsoft's DNS Challenge)\n",
    "model = ort.InferenceSession(\"dns_model.onnx\")\n",
    "\n",
    "# Define frame size for real-time processing\n",
    "frame_size = 512  # Example frame size\n",
    "\n",
    "# Process the audio in frames\n",
    "def denoise_audio(audio, model):\n",
    "    processed_audio = []\n",
    "    \n",
    "    for i in range(0, len(audio), frame_size):\n",
    "        frame = audio[i:i + frame_size]\n",
    "        if len(frame) < frame_size:\n",
    "            frame = np.pad(frame, (0, frame_size - len(frame)))\n",
    "        frame = frame.reshape(1, 1, frame_size).astype(np.float32)\n",
    "        \n",
    "        # Model inference\n",
    "        denoised_frame = model.run(None, {\"input\": frame})[0].flatten()\n",
    "        processed_audio.extend(denoised_frame)\n",
    "\n",
    "    return np.array(processed_audio)\n",
    "\n",
    "# Denoise the audio\n",
    "denoised_audio = denoise_audio(audio, model)\n",
    "\n",
    "# Save the denoised audio\n",
    "sf.write(\"output_audio4\", denoised_audio, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25549cad-452e-4f17-a33c-328c2238c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.inference.separation import SepformerSeparation as separator\n",
    "import torchaudio\n",
    "\n",
    "model = separator.from_hparams(source=\"speechbrain/sepformer-dns4-16k-enhancement\", savedir='pretrained_models/sepformer-dns4-16k-enhancement')\n",
    "\n",
    "# for custom file, change path\n",
    "est_sources = model.separate_file(path='speechbrain/sepformer-dns4-16k-enhancement/example_dns4-16k.wav') \n",
    "\n",
    "torchaudio.save(\"enhanced_dns4-16k.wav\", est_sources[:, :, 0].detach().cpu(), 16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483d552-5180-4a3b-8579-688d985a4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from speechbrain.pretrained import SpectralMaskGenerator\n",
    "\n",
    "# Load the DNS model (make sure to adjust for your specific model and settings)\n",
    "dns_model = SpectralMaskGenerator.from_hparams(source=\"speechbrain/VoiceEnhancement\", savedir=\"dns_model\")\n",
    "\n",
    "# Set parameters\n",
    "sample_rate = 16000  # Common sample rate for speech processing\n",
    "frame_duration = 0.02  # Frame duration in seconds\n",
    "frame_size = int(sample_rate * frame_duration)\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    # Convert input to tensor and perform noise suppression\n",
    "    noisy_audio = torch.tensor(indata.T)\n",
    "    enhanced_audio = dns_model(noisy_audio)\n",
    "\n",
    "    # Output the enhanced audio\n",
    "    sd.play(enhanced_audio.detach().numpy().T, samplerate=sample_rate)\n",
    "\n",
    "# Start the input stream\n",
    "with sd.InputStream(callback=callback, channels=1, samplerate=sample_rate):\n",
    "    print(\"Press Ctrl+C to stop\")\n",
    "    sd.sleep(100000)  # Keep the stream open for a while\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d74bb6-c253-4575-910d-fe5553fdbc21",
   "metadata": {},
   "source": [
    "### Audio API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57c5232-bc17-40f7-8473-1986ba6f92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests  # Used for making HTTP requests\n",
    "import json  # Used for working with JSON data\n",
    "\n",
    "# Define constants for the script\n",
    "CHUNK_SIZE = 1024  # Size of chunks to read/write at a time\n",
    "XI_API_KEY = \"sk_632eb96bd5ff0ac2d1695753c761f837209eba3287b3c6a4\"  # Your API key for authentication\n",
    "VOICE_ID = \"cgSgspJ2msm6clMCkdW9\"  # ID of the voice model to use\n",
    "TEXT_TO_SPEAK = \"Hello,my name is charlie.I am your personal assistant.\"  # Text you want to convert to speech\n",
    "OUTPUT_PATH_MP3 = \"output.mp3\"  # Path to save the output audio file\n",
    "\n",
    "# Construct the URL for the Text-to-Speech API request\n",
    "tts_url = f\"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream\"\n",
    "\n",
    "# Set up headers for the API request, including the API key for authentication\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"xi-api-key\": XI_API_KEY\n",
    "}\n",
    "\n",
    "# Set up the data payload for the API request, including the text and voice settings\n",
    "data = {\n",
    "    \"text\": TEXT_TO_SPEAK,\n",
    "    \"model_id\": \"eleven_multilingual_v2\",\n",
    "    \"voice_settings\": {\n",
    "        \"stability\": 0.5,\n",
    "        \"similarity_boost\": 0.8,\n",
    "        \"style\": 0.0,\n",
    "        \"use_speaker_boost\": True\n",
    "    }\n",
    "}\n",
    "# Make the POST request to the TTS API with headers and data, enabling streaming response\n",
    "response = requests.post(tts_url, headers=headers, json=data, stream=True)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.ok:\n",
    "    # Open the output file in write-binary mode\n",
    "    with open(OUTPUT_PATH_MP3, \"wb\") as f:\n",
    "        # Read the response in chunks and write to the file\n",
    "        for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "            f.write(chunk)\n",
    "else:\n",
    "    # Print the error message if the request was not successful\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25615745-7acb-497b-9bf5-79276c5d1282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio stream saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import requests  # Used for making HTTP requests\n",
    "import json  # Used for working with JSON data\n",
    "\n",
    "# Define constants for the script\n",
    "CHUNK_SIZE = 1024  # Size of chunks to read/write at a time\n",
    "XI_API_KEY = \"sk_632eb96bd5ff0ac2d1695753c761f837209eba3287b3c6a4\"  # Your API key for authentication\n",
    "VOICE_ID = \"cgSgspJ2msm6clMCkdW9\"  # ID of the voice model to use\n",
    "TEXT_TO_SPEAK = 'Vision AI, also known as \"computer vision,\" is a field of artificial intelligence that enables computers to interpret and analyze visual data like images and videos, essentially allowing them to \"see\" and understand their surroundings, similar to how humans do, by identifying and classifying objects within the visual input; this technology is used for tasks like facial recognition, object detection, image classification, and more, with applications in various industries like retail, healthcare, and security.'  # Text you want to convert to speech\n",
    "OUTPUT_PATH = \"output2.mp3\"  # Path to save the output audio file\n",
    "\n",
    "# Construct the URL for the Text-to-Speech API request\n",
    "tts_url = f\"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream\"\n",
    "\n",
    "# Set up headers for the API request, including the API key for authentication\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"xi-api-key\": XI_API_KEY\n",
    "}\n",
    "\n",
    "# Set up the data payload for the API request, including the text and voice settings\n",
    "data = {\n",
    "    \"text\": TEXT_TO_SPEAK,\n",
    "    \"model_id\": \"eleven_multilingual_v2\",\n",
    "    \"voice_settings\": {\n",
    "        \"stability\": 0.5,\n",
    "        \"similarity_boost\": 0.8,\n",
    "        \"style\": 0.0,\n",
    "        \"use_speaker_boost\": True\n",
    "    }\n",
    "}\n",
    "# Make the POST request to the TTS API with headers and data, enabling streaming response\n",
    "response = requests.post(tts_url, headers=headers, json=data, stream=True)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.ok:\n",
    "    # Open the output file in write-binary mode\n",
    "    with open(OUTPUT_PATH, \"wb\") as f:\n",
    "        # Read the response in chunks and write to the file\n",
    "        for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "            f.write(chunk)\n",
    "    # Inform the user of success\n",
    "    print(\"Audio stream saved successfully.\")\n",
    "else:\n",
    "    # Print the error message if the request was not successful\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e4d7da-0aed-4ae8-b628-136e81506244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c82c58-db3c-490a-9408-37593b3e0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222ff02-a4c8-45f8-b7c7-4e36616b3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the audio file using simpleaudio\n",
    "wave_obj = sa.WaveObject.from_wave_file(\"output_audio1.wav\")\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()  # Wait until playback finishes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1634f109-2b61-4ae4-bab5-6bf425d9a218",
   "metadata": {},
   "source": [
    "### PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d21d7f9-ef65-4891-a767-25687eb94a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio converted and saved as output.mkv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Play the sound by writing the audio data to the stream\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m data \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 34\u001b[0m     \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     data \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39mreadframes(chunk)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Close and terminate the stream\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vbva\\Lib\\site-packages\\pyaudio\\__init__.py:550\u001b[0m, in \u001b[0;36mPyAudio.Stream.write\u001b[1;34m(self, frames, num_frames, exception_on_underflow)\u001b[0m\n\u001b[0;32m    547\u001b[0m     width \u001b[38;5;241m=\u001b[39m get_sample_size(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format)\n\u001b[0;32m    548\u001b[0m     num_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(frames) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channels \u001b[38;5;241m*\u001b[39m width))\n\u001b[1;32m--> 550\u001b[0m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexception_on_underflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "# Convert to WAV\n",
    "OUTPUT_PATH_MP3 = \"output.mp3\"\n",
    "OUTPUT_PATH_MKV = \"output.mkv\"\n",
    "audio = AudioSegment.from_file(OUTPUT_PATH_MP3, format=\"mp3\")\n",
    "audio.export(OUTPUT_PATH_MKV, format=\"wav\")\n",
    "print(f\"Audio converted and saved as {OUTPUT_PATH_MKV}\")\n",
    "\n",
    "\n",
    "\n",
    "# Set chunk size of 1024 samples per data frame\n",
    "chunk = 1024  \n",
    "\n",
    "# Open the sound file \n",
    "wf = wave.open(OUTPUT_PATH_MKV, 'rb')\n",
    "\n",
    "# Create an interface to PortAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open a .Stream object to write the WAV file to\n",
    "# 'output = True' indicates that the sound will be played rather than recorded\n",
    "stream = p.open(format = p.get_format_from_width(wf.getsampwidth()),\n",
    "                channels = wf.getnchannels(),\n",
    "                rate = wf.getframerate(),\n",
    "                output = True)\n",
    "\n",
    "# Read data in chunks\n",
    "data = wf.readframes(chunk)\n",
    "\n",
    "# Play the sound by writing the audio data to the stream\n",
    "while data != '':\n",
    "    stream.write(data)\n",
    "    data = wf.readframes(chunk)\n",
    "\n",
    "# Close and terminate the stream\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca43376-ec42-43bc-8058-e68bdd4263ad",
   "metadata": {},
   "source": [
    "### PyDub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bb955e-e778-4a3b-b999-644416fd9f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete!\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Point to ffmpeg executable directly\n",
    "# AudioSegment.converter = r\"C:\\ffmpeg\\ffmpeg-master-latest-win64-gpl\\bin\\ffmpeg.exe\"  \n",
    "# AudioSegment.ffprobe = r\"C:\\ffmpeg\\ffmpeg-master-latest-win64-gpl\\bin\\ffprobe.exe\"\n",
    "\n",
    "# Convert MP3 to WAV\n",
    "audio = AudioSegment.from_file(\"output.mp3\", format=\"mp3\")\n",
    "audio.export(\"output.wav\", format=\"wav\")\n",
    "print(\"Conversion complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4acd075-42fc-4ac1-ad85-9d79449e86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def text_to_speech(text, api_key, voice_id, output_path=\"output.mp3\"):\n",
    "    \"\"\"\n",
    "    Converts text to speech using the ElevenLabs Text-to-Speech API.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to convert to speech.\n",
    "        api_key (str): Your ElevenLabs API key.\n",
    "        voice_id (str): The voice ID to use for speech synthesis.\n",
    "        output_path (str): The path where the audio file will be saved. Defaults to \"output.mp3\".\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the generated audio file.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the API request fails or encounters an error.\n",
    "    \"\"\"\n",
    "    tts_url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"xi-api-key\": api_key\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"text\": text,\n",
    "        \"model_id\": \"eleven_multilingual_v2\",\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.5,\n",
    "            \"similarity_boost\": 0.8,\n",
    "            \"style\": 0.0,\n",
    "            \"use_speaker_boost\": True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(tts_url, headers=headers, json=data, stream=True)\n",
    "        if response.ok:\n",
    "            # Save the audio to the specified file\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            print(f\"Audio saved to {output_path}\")\n",
    "            return output_path\n",
    "        else:\n",
    "            # Raise an exception if the API request fails\n",
    "            raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "    except requests.RequestException as e:\n",
    "        raise Exception(f\"Request failed: {e}\")\n",
    "\n",
    "# Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Replace with your actual API key and voice ID\n",
    "#     XI_API_KEY = \"sk_632eb96bd5ff0ac2d1695753c761f837209eba3287b3c6a4\"\n",
    "#     VOICE_ID = \"cgSgspJ2msm6clMCkdW9\"\n",
    "    \n",
    "#     # Input text\n",
    "#     input_text = \"Hello, my name is Charlie. I am your personal assistant.What i can help you\"\n",
    "    \n",
    "#     # Generate speech\n",
    "#     audio_file_path = text_to_speech(input_text, XI_API_KEY, VOICE_ID)\n",
    "#     print(f\"Generated audio file: {audio_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf9cad0-2cf7-49e4-881b-19e718a98e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio converted and saved as output.wav\n",
      "Audio playback completed.\n",
      "Processed audio saved at: output.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def convert_and_play_audio(input_audio_path, output_audio_path=\"output.wav\"):\n",
    "    \"\"\"\n",
    "    Converts an audio file to WAV format and plays it.\n",
    "\n",
    "    Args:\n",
    "        input_audio_path (str): Path to the input audio file.\n",
    "        output_audio_path (str): Path to save the converted WAV file. Defaults to \"output.wav\".\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved WAV file.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If any error occurs during processing or playback.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to WAV format\n",
    "        audio = AudioSegment.from_file(input_audio_path)\n",
    "        audio.export(output_audio_path, format=\"wav\")\n",
    "        print(f\"Audio converted and saved as {output_audio_path}\")\n",
    "\n",
    "        # Play the WAV file\n",
    "        chunk = 1024  # Chunk size for reading audio\n",
    "\n",
    "        # Open the sound file\n",
    "        wf = wave.open(output_audio_path, 'rb')\n",
    "\n",
    "        # Create an interface to PortAudio\n",
    "        p = pyaudio.PyAudio()\n",
    "\n",
    "        # Open a .Stream object to write the WAV file to\n",
    "        stream = p.open(\n",
    "            format=p.get_format_from_width(wf.getsampwidth()),\n",
    "            channels=wf.getnchannels(),\n",
    "            rate=wf.getframerate(),\n",
    "            output=True\n",
    "        )\n",
    "\n",
    "        # Read and play audio in chunks\n",
    "        data = wf.readframes(chunk)\n",
    "        while data:\n",
    "            stream.write(data)\n",
    "            data = wf.readframes(chunk)\n",
    "\n",
    "        # Close and terminate the stream\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        print(\"Audio playback completed.\")\n",
    "        return output_audio_path\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input and output file paths\n",
    "    INPUT_AUDIO_PATH = \"output.mp3\"\n",
    "    OUTPUT_AUDIO_PATH = \"output.wav\"\n",
    "    \n",
    "    # Convert and play audio\n",
    "    try:\n",
    "        result_path = convert_and_play_audio(INPUT_AUDIO_PATH, OUTPUT_AUDIO_PATH)\n",
    "        print(f\"Processed audio saved at: {result_path}\")\n",
    "    except Exception as error:\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89e66214-7160-444c-b8c4-8ae7a85eac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to output.mp3\n",
      "Generated audio file: output.mp3\n",
      "Audio converted and saved as output.wav\n",
      "Audio playback completed.\n",
      "Processed audio saved at: output.wav\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual API key and voice ID\n",
    "    XI_API_KEY = \"sk_632eb96bd5ff0ac2d1695753c761f837209eba3287b3c6a4\"\n",
    "    VOICE_ID = \"cgSgspJ2msm6clMCkdW9\"\n",
    "    \n",
    "    # Input text\n",
    "    input_text = \"Hello, my name is Charlie. I am your personal assistant.What i can help you\"\n",
    "    \n",
    "    # Generate speech\n",
    "    audio_file_path = text_to_speech(input_text, XI_API_KEY, VOICE_ID)\n",
    "    print(f\"Generated audio file: {audio_file_path}\")\n",
    "\n",
    "    INPUT_AUDIO_PATH = audio_file_path\n",
    "    OUTPUT_AUDIO_PATH = \"output.wav\"\n",
    "    \n",
    "    # Convert and play audio\n",
    "    try:\n",
    "        result_path = convert_and_play_audio(INPUT_AUDIO_PATH, OUTPUT_AUDIO_PATH)\n",
    "        print(f\"Processed audio saved at: {result_path}\")\n",
    "    except Exception as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996d98f-8a5f-4559-a741-c381b575be33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
